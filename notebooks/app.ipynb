{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73261947",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# app.ipynb\n",
    "\n",
    "# --- 1. Import libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, median_absolute_error\n",
    "# Optional for residual correction later:\n",
    "# from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your CSV is elsewhere, change the path\n",
    "CSV_PATH = \"activities.csv\"\n",
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea251b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_time(sec: float) -> str:\n",
    "    \"\"\"Convert seconds to M:SS string.\"\"\"\n",
    "    sec = float(sec)\n",
    "    m = int(sec // 60)\n",
    "    s = int(round(sec - 60*m))\n",
    "    if s == 60:\n",
    "        m, s = m + 1, 0\n",
    "    return f\"{m}:{s:02d}\"\n",
    "\n",
    "def clean_runs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep sensible RUN activities and prefer Moving Time over Elapsed Time.\n",
    "    Applies:\n",
    "      - choose time column (Moving Time if available)\n",
    "      - numeric coercion\n",
    "      - positive values\n",
    "      - 2–25 km\n",
    "      - <4 hours\n",
    "      - pause filter if both times exist (Elapsed/Moving < 1.05)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Activity type (fallback to assuming runs if missing)\n",
    "    if \"Activity Type\" in df.columns:\n",
    "        df = df[df[\"Activity Type\"] == \"Run\"].copy()\n",
    "\n",
    "    # Time column preference\n",
    "    time_col = \"Moving Time\" if \"Moving Time\" in df.columns else \"Elapsed Time\"\n",
    "    if time_col not in df.columns:\n",
    "        raise ValueError(\"Neither 'Moving Time' nor 'Elapsed Time' found in CSV.\")\n",
    "\n",
    "    # Coerce numeric\n",
    "    df[\"TimeSec\"]  = pd.to_numeric(df[time_col], errors=\"coerce\")\n",
    "    if \"Distance\" not in df.columns:\n",
    "        raise ValueError(\"Column 'Distance' (km) not found in CSV.\")\n",
    "    df[\"Distance\"] = pd.to_numeric(df[\"Distance\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop invalid\n",
    "    df = df.dropna(subset=[\"TimeSec\", \"Distance\"])\n",
    "    df = df[(df[\"TimeSec\"] > 0) & (df[\"Distance\"] > 0)]\n",
    "\n",
    "    # Practical bounds\n",
    "    df = df[(df[\"Distance\"] >= 2.0) & (df[\"Distance\"] <= 25.0)]\n",
    "    df = df[df[\"TimeSec\"] <= 4 * 3600]\n",
    "\n",
    "    # Stricter pause filter if both times exist\n",
    "    if {\"Elapsed Time\", \"Moving Time\"}.issubset(df.columns):\n",
    "        et = pd.to_numeric(df[\"Elapsed Time\"], errors=\"coerce\")\n",
    "        mt = pd.to_numeric(df[\"Moving Time\"], errors=\"coerce\")\n",
    "        pause_ratio = et / mt\n",
    "        df = df[pause_ratio < 1.05]  # <=5% paused time\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def fit_personal_curve(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Fit T = c * D^k via log–log linear regression, with a simple residual trim for robustness.\n",
    "    Returns: k (slope), c (scale), inlier_mask (boolean array of df length).\n",
    "    \"\"\"\n",
    "    D = df[\"Distance\"].to_numpy()\n",
    "    T = df[\"TimeSec\"].to_numpy()\n",
    "    logD, logT = np.log(D), np.log(T)\n",
    "\n",
    "    # First pass\n",
    "    k1, logc1 = np.polyfit(logD, logT, 1)\n",
    "    pred1 = k1 * logD + logc1\n",
    "    resid = logT - pred1\n",
    "\n",
    "    # Trim extreme residuals (keep central 96%)\n",
    "    lo, hi = np.quantile(resid, [0.02, 0.98])\n",
    "    mask = (resid >= lo) & (resid <= hi)\n",
    "\n",
    "    # Refit on inliers\n",
    "    k, logc = np.polyfit(logD[mask], logT[mask], 1)\n",
    "    c = np.exp(logc)\n",
    "    return k, c, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-run 5K-equivalents if not already done\n",
    "D = runs[\"Distance\"].to_numpy()\n",
    "T = runs[\"TimeSec\"].to_numpy()\n",
    "T5_each_sec = T * (5.0 / D) ** k\n",
    "\n",
    "# Fastest 30% (or change to 20%) to focus on race-like efforts\n",
    "top_n = max(5, int(0.30 * len(T5_each_sec)))\n",
    "race_like_T5 = pd.Series(T5_each_sec).nsmallest(top_n).to_numpy()\n",
    "personal_5k_racelike_sec = float(np.median(race_like_T5))\n",
    "print(\"Race-like personal 5K:\", fmt_time(personal_5k_racelike_sec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058dd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "feat_cols = [c for c in [\"Elevation Gain\",\"Weather Temperature\"] if c in runs.columns]\n",
    "if len(feat_cols) >= 1:\n",
    "    resid_min = (T - (c * (D**k))) / 60.0\n",
    "    Xr = runs[feat_cols].copy().fillna(runs[feat_cols].median(numeric_only=True))\n",
    "    huber = HuberRegressor().fit(Xr, resid_min)\n",
    "\n",
    "    typical = pd.DataFrame([Xr.median(numeric_only=True).to_dict()])[feat_cols]\n",
    "    delta_min = float(huber.predict(typical)[0])\n",
    "\n",
    "    T5_curve_sec = c * (5.0**k)\n",
    "    personal_5k_adjusted_sec = T5_curve_sec + 60 * delta_min\n",
    "    print(\"Adjusted personal 5K (typical elev/temp):\", fmt_time(personal_5k_adjusted_sec))\n",
    "    print(\"Residual coeffs (min per unit):\", dict(zip(feat_cols, np.round(huber.coef_, 4))))\n",
    "else:\n",
    "    print(\"Residual correction skipped (no Elevation/Temperature columns).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = clean_runs(df_raw)\n",
    "print(f\"Runs after cleaning: {len(runs)}\")\n",
    "\n",
    "k, c, inliers = fit_personal_curve(runs)\n",
    "print(f\"Personal distance–time exponent k = {k:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feda27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_target = 5.0\n",
    "T5_curve_sec = c * (D_target ** k)  # single ability from curve\n",
    "\n",
    "# Per-run 5K equivalents using your personal k\n",
    "T  = runs[\"TimeSec\"].to_numpy()\n",
    "D  = runs[\"Distance\"].to_numpy()\n",
    "T5_each_sec = T * (D_target / D) ** k\n",
    "\n",
    "T5_median_sec = float(np.median(T5_each_sec))\n",
    "if len(T5_each_sec) >= 10:\n",
    "    s = pd.Series(T5_each_sec).sort_values()\n",
    "    lo, hi = int(0.10*len(s)), int(0.90*len(s))\n",
    "    T5_trim_sec = float(s.iloc[lo:hi].mean())\n",
    "else:\n",
    "    T5_trim_sec = float(np.mean(T5_each_sec))\n",
    "\n",
    "print(\"Personal 5K — curve:\", fmt_time(T5_curve_sec))\n",
    "print(\"Personal 5K — median of equivalents:\", fmt_time(T5_median_sec))\n",
    "print(\"Personal 5K — trimmed mean (10–90%):\", fmt_time(T5_trim_sec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00826028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "\n",
    "def score_single_value(T5_single_sec):\n",
    "    band = runs[(runs[\"Distance\"]>=4.8) & (runs[\"Distance\"]<=5.2)].copy()\n",
    "    # drop obvious easy 5Ks (jogs): pace ≥ 9:00 min/km\n",
    "    pace = (band[\"TimeSec\"]/60.0) / band[\"Distance\"]\n",
    "    band = band[pace < 9.0]\n",
    "    if len(band) < 3:\n",
    "        return {\"n\": len(band), \"MAE\": None, \"MedAE\": None, \"MAPE\": None}\n",
    "    y_true = (band[\"TimeSec\"]/60.0).to_numpy()\n",
    "    y_pred = np.full_like(y_true, T5_single_sec/60.0)\n",
    "    return {\n",
    "        \"n\": len(band),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "        \"MAPE\": float(np.mean(np.abs((y_true - y_pred)/y_true))*100),\n",
    "    }\n",
    "\n",
    "# Baseline curve estimate\n",
    "T5_curve = c*(5.0**k)\n",
    "print(\"Curve:\", score_single_value(T5_curve))\n",
    "\n",
    "# Race-like variant\n",
    "if 'personal_5k_racelike_sec' in locals():\n",
    "    print(\"Race-like:\", score_single_value(personal_5k_racelike_sec))\n",
    "\n",
    "# Adjusted (elev/temp) variant\n",
    "if 'personal_5k_adjusted_sec' in locals():\n",
    "    print(\"Adjusted (typical elev/temp):\", score_single_value(personal_5k_adjusted_sec))\n",
    "\n",
    "# Recent window variant\n",
    "if 'T5_recent' in locals():\n",
    "    print(\"Recent-window:\", score_single_value(T5_recent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance vs Time (min) with fitted curve\n",
    "grid = np.linspace(max(2.0, runs[\"Distance\"].min()),\n",
    "                   min(25.0, max(25.0, runs[\"Distance\"].max())), 200)\n",
    "curve_min = (c * (grid ** k)) / 60.0\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(runs[\"Distance\"], runs[\"TimeSec\"]/60.0, alpha=0.6, label=\"Runs\")\n",
    "plt.plot(grid, curve_min, lw=2, label=\"Personal fit\")\n",
    "plt.title(\"Distance vs Time (minutes)\")\n",
    "plt.xlabel(\"Distance (km)\")\n",
    "plt.ylabel(\"Time (min)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Histogram of per-activity 5K equivalents (minutes)\n",
    "plt.figure()\n",
    "plt.hist(T5_each_sec/60.0, bins=20)\n",
    "plt.title(\"Distribution of 5K-Equivalent Times (minutes)\")\n",
    "plt.xlabel(\"5K-equivalent time (min)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f2485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² of the log–log fit (over all cleaned runs)\n",
    "logD = np.log(runs[\"Distance\"].to_numpy())\n",
    "logT = np.log(runs[\"TimeSec\"].to_numpy())\n",
    "logT_pred = np.log(c) + k*logD\n",
    "r2 = r2_score(logT, logT_pred)\n",
    "print(f\"R² (log–log): {r2:.3f}\")\n",
    "\n",
    "# Evaluate on actual ~5Ks (tighter band + exclude very slow 'easy' 5Ks)\n",
    "band = runs[(runs[\"Distance\"] >= 4.8) & (runs[\"Distance\"] <= 5.2)].copy()\n",
    "pace_min_per_km = (band[\"TimeSec\"]/60.0) / band[\"Distance\"]\n",
    "band = band[pace_min_per_km < 9.0]  # drop easy jog 5Ks; adjust threshold as you like\n",
    "\n",
    "if len(band) >= 3:\n",
    "    y_true = (band[\"TimeSec\"]/60.0).to_numpy()\n",
    "    y_pred = np.full_like(y_true, T5_curve_sec/60.0)  # compare to single number\n",
    "    mae   = mean_absolute_error(y_true, y_pred)\n",
    "    medae = median_absolute_error(y_true, y_pred)\n",
    "    mape  = float(np.mean(np.abs((y_true - y_pred)/y_true))*100)\n",
    "\n",
    "    print(f\"~5K accuracy (n={len(band)}): MAE={mae:.2f} min, MedAE={medae:.2f} min, MAPE={mape:.1f}%\")\n",
    "else:\n",
    "    print(\"Not enough ~5Ks after filtering to compute hold-out metrics (need ≥3).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea726fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only runs with a date column\n",
    "date_col = None\n",
    "for ctry in [\"Activity Date\", \"Start Date\", \"Start Time\", \"Date\"]:\n",
    "    if ctry in runs.columns:\n",
    "        date_col = ctry\n",
    "        break\n",
    "\n",
    "if date_col is not None:\n",
    "    rs = runs.copy()\n",
    "    rs[date_col] = pd.to_datetime(rs[date_col], errors=\"coerce\")\n",
    "    rs = rs.dropna(subset=[date_col]).sort_values(date_col)\n",
    "    if len(rs) >= 20:\n",
    "        cut = int(0.7 * len(rs))  # 70/30 split\n",
    "        train, test = rs.iloc[:cut].copy(), rs.iloc[cut:].copy()\n",
    "\n",
    "        k_tr, c_tr, _ = fit_personal_curve(train)\n",
    "        T5_single_min_tr = (c_tr * (5.0**k_tr)) / 60.0\n",
    "\n",
    "        band_te = test[(test[\"Distance\"] >= 4.8) & (test[\"Distance\"] <= 5.2)].copy()\n",
    "        pace_te = (band_te[\"TimeSec\"]/60.0) / band_te[\"Distance\"]\n",
    "        band_te = band_te[pace_te < 9.0]\n",
    "\n",
    "        if len(band_te) >= 3:\n",
    "            y_true = (band_te[\"TimeSec\"]/60.0).to_numpy()\n",
    "            y_pred = np.full_like(y_true, T5_single_min_tr)\n",
    "            print(\"Time-split backtest on recent ~5Ks:\")\n",
    "            print(\"  MAE:\", round(mean_absolute_error(y_true, y_pred), 2), \"min\")\n",
    "        else:\n",
    "            print(\"Time-split: not enough recent ~5Ks for backtest.\")\n",
    "    else:\n",
    "        print(\"Time-split: not enough runs with dates (need ≥20).\")\n",
    "else:\n",
    "    print(\"No suitable date column found; skipping time-split backtest.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on your fastest efforts to reflect race ability (top 30% fastest 5K equivalents)\n",
    "s = pd.Series(T5_each_sec)\n",
    "fast_slice = s.nsmallest(max(5, int(0.3*len(s))))\n",
    "print(\"Personal 5K (fastest 30% median):\", fmt_time(float(np.median(fast_slice))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have 'Elevation Gain' and 'Weather Temperature', you can learn how they shift your times.\n",
    "# Uncomment the HuberRegressor import at the top before running.\n",
    "\n",
    "if all(col in runs.columns for col in [\"Elevation Gain\", \"Weather Temperature\"]):\n",
    "    # Residual (minutes) vs the curve across all distances\n",
    "    resid_min = (runs[\"TimeSec\"].to_numpy() - (c * (runs[\"Distance\"].to_numpy()**k))) / 60.0\n",
    "    Xr = runs[[\"Elevation Gain\", \"Weather Temperature\"]].copy()\n",
    "    Xr = Xr.fillna(Xr.median(numeric_only=True))  # simple imputation\n",
    "    try:\n",
    "        from sklearn.linear_model import HuberRegressor\n",
    "        huber = HuberRegressor().fit(Xr, resid_min)\n",
    "        typical = pd.DataFrame(\n",
    "            [[Xr[\"Elevation Gain\"].median(), Xr[\"Weather Temperature\"].median()]],\n",
    "            columns=[\"Elevation Gain\", \"Weather Temperature\"]\n",
    "        )\n",
    "        delta = float(huber.predict(typical)[0])  # minutes\n",
    "        adjusted_min = (T5_curve_sec/60.0) + delta\n",
    "        print(\"Adjusted personal 5K (typical elev/temp):\", fmt_time(adjusted_min*60))\n",
    "        print(\"Residual model coefficients (min per unit):\",\n",
    "              dict(zip([\"Elevation Gain\",\"Weather Temperature\"], np.round(huber.coef_, 4))))\n",
    "    except Exception as e:\n",
    "        print(\"Residual correction step skipped due to error:\", e)\n",
    "else:\n",
    "    print(\"Residual correction: missing Elevation Gain and/or Weather Temperature.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Strava venv)",
   "language": "python",
   "name": "strava"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
